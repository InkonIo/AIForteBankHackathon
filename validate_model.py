"""
üîç –ì–õ–£–ë–û–ö–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø ML-–ú–û–î–ï–õ–ò
–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–∞–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve
from sklearn.metrics import (confusion_matrix, classification_report, 
                            roc_curve, auc, precision_recall_curve)
import catboost as cb
import lightgbm as lgb
import psycopg2
import warnings
import json
from pathlib import Path
warnings.filterwarnings('ignore')

from sklearn.base import BaseEstimator, ClassifierMixin

# ==================== –û–ë–Å–†–¢–ö–ê –î–õ–Ø LIGHTGBM ====================

class LGBMWrapper(BaseEstimator, ClassifierMixin):
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è LightGBM Booster –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å sklearn"""
    
    def __init__(self, model_path):
        self.model_path = model_path
        self.booster_ = None
        self.classes_ = np.array([0, 1])
        self.n_classes_ = 2
        
    def fit(self, X, y):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º pre-trained –º–æ–¥–µ–ª—å (–Ω–µ –æ–±—É—á–∞–µ–º –∑–∞–Ω–æ–≤–æ)"""
        if self.booster_ is None:
            self.booster_ = lgb.Booster(model_file=self.model_path)
        return self
    
    def predict_proba(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏"""
        if self.booster_ is None:
            self.booster_ = lgb.Booster(model_file=self.model_path)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ numpy –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(X, pd.DataFrame):
            X_array = X.values
        else:
            X_array = X
            
        proba = self.booster_.predict(X_array)
        return np.vstack([1 - proba, proba]).T
    
    def predict(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å—ã"""
        proba = self.predict_proba(X)[:, 1]
        return (proba >= 0.5).astype(int)

# ==================== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ====================

def load_data_from_db():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL –ë–î"""
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î...")
    
    DB_CONFIG = {
        'host': 'localhost',
        'port': 5432,
        'database': 'fraud_db',
        'user': 'postgres',
        'password': 'Alikhancool20!'
    }
    
    conn = psycopg2.connect(**DB_CONFIG)
    
    query = """
    SELECT 
        t.id,
        t.transaction_id,
        t.customer_id,
        t.recipient_id,
        t.amount,
        t.transaction_datetime,
        t.is_fraud,
        
        -- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        EXTRACT(HOUR FROM t.transaction_datetime) as hour,
        EXTRACT(MINUTE FROM t.transaction_datetime) as minute,
        EXTRACT(DOW FROM t.transaction_datetime) as day_of_week,
        EXTRACT(DAY FROM t.transaction_datetime) as day_of_month,
        EXTRACT(MONTH FROM t.transaction_datetime) as month,
        
        -- –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        cb.avg_logins_per_day_30d,
        cb.avg_logins_per_day_7d,
        cb.avg_session_interval_sec,
        cb.burstiness_score,
        cb.exp_weighted_avg_interval,
        cb.fano_factor,
        cb.interval_zscore,
        cb.latest_os_version,
        cb.latest_phone_model,
        cb.login_freq_change_ratio,
        cb.login_ratio_7d_30d,
        cb.logins_last_30_days,
        cb.logins_last_7_days,
        cb.session_interval_std,
        cb.session_interval_variance,
        cb.unique_os_versions_30d,
        cb.unique_phone_models_30d
        
    FROM transactions t
    LEFT JOIN customer_behavior_patterns cb 
        ON t.customer_id = cb.customer_id 
        AND DATE(t.transaction_datetime) = cb.trans_date  
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
    df['transaction_datetime'] = pd.to_datetime(df['transaction_datetime'])
    df['is_fraud'] = df['is_fraud'].astype(bool)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    print(f"   –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö: {df['is_fraud'].sum()}")
    print(f"   –ß–∏—Å—Ç—ã—Ö: {(~df['is_fraud']).sum()}")
    
    return df

# ==================== FEATURE ENGINEERING ====================

def engineer_features_advanced(df):
    """–°–æ–∑–¥–∞—Ç—å –†–ê–°–®–ò–†–ï–ù–ù–´–ô –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ–ø–∏—è –∏–∑ train_improved_model.py)"""
    
    print("\nüîß Feature Engineering...")
    
    df = df.copy()
    
    # ========== –°–ù–ê–ß–ê–õ–ê –ó–ê–ü–û–õ–ù–Ø–ï–ú –ü–†–û–ü–£–°–ö–ò ==========
    df = df.fillna(0)
    
    # ========== –ì–†–£–ü–ü–ê 1: –ü–†–ò–ó–ù–ê–ö–ò –°–£–ú–ú–´ ==========
    
    # –ë–∞–∑–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    df['amount_log'] = np.log(df['amount'] + 1)
    df['amount_sqrt'] = np.sqrt(df['amount'])
    df['amount_cbrt'] = np.cbrt(df['amount'])
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—É–º–º (–ò–°–ü–†–ê–í–õ–ï–ù–û!)
    df['amount_category'] = pd.cut(df['amount'], 
                                    bins=[0, 10000, 50000, 100000, 500000, float('inf')],
                                    labels=[0, 1, 2, 3, 4])
    df['amount_category'] = df['amount_category'].fillna(0).astype(int)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ–∫—Ä—É–≥–ª–æ—Å—Ç–∏
    df['is_round_100'] = (df['amount'] % 100 == 0).astype(int)
    df['is_round_1000'] = (df['amount'] % 1000 == 0).astype(int)
    df['is_round_10000'] = (df['amount'] % 10000 == 0).astype(int)
    
    # ========== –ì–†–£–ü–ü–ê 2: –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========
    
    # –ë–∞–∑–æ–≤—ã–µ —Ñ–ª–∞–≥–∏
    df['is_night'] = ((df['hour'] >= 23) | (df['hour'] < 6)).astype(int)
    df['is_early_morning'] = ((df['hour'] >= 6) & (df['hour'] < 9)).astype(int)
    df['is_morning'] = ((df['hour'] >= 9) & (df['hour'] < 12)).astype(int)
    df['is_afternoon'] = ((df['hour'] >= 12) & (df['hour'] < 18)).astype(int)
    df['is_evening'] = ((df['hour'] >= 18) & (df['hour'] < 23)).astype(int)
    df['is_weekend'] = (df['day_of_week'].isin([5, 6])).astype(int)
    
    # –û–ø–∞—Å–Ω—ã–µ —á–∞—Å—ã (–ø–∏–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: 2-5 —É—Ç—Ä–∞)
    df['is_peak_fraud_hour'] = ((df['hour'] >= 2) & (df['hour'] < 5)).astype(int)
    
    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    
    # ========== –ì–†–£–ü–ü–ê 3: –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò ==========
    
    # –§–ª–∞–≥ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
    df['has_behavior_data'] = ((df['logins_last_7_days'] > 0) | 
                                (df['logins_last_30_days'] > 0)).astype(int)
    
    # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç–∞
    df['login_activity_score'] = df['logins_last_7_days'] / (df['logins_last_30_days'] + 1)
    
    # –ê–Ω–æ–º–∞–ª–∏–∏ –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏
    df['is_zero_activity'] = ((df['logins_last_7_days'] == 0) & 
                               (df['logins_last_30_days'] == 0)).astype(int)
    
    df['is_high_burstiness'] = (df['burstiness_score'] > 0.7).astype(int)
    df['is_unusual_interval'] = (np.abs(df['interval_zscore']) > 2).astype(int)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
    df['has_os_data'] = (df['latest_os_version'] != 0).astype(int)
    df['has_phone_data'] = (df['latest_phone_model'] != 0).astype(int)
    df['device_diversity'] = df['unique_os_versions_30d'] + df['unique_phone_models_30d']
    df['is_multi_device'] = (df['device_diversity'] > 2).astype(int)
    
    # ========== –ì–†–£–ü–ü–ê 4: –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========
    
    # –ù–æ—á—å + –±–æ–ª—å—à–∞—è —Å—É–º–º–∞
    df['night_large_amount'] = (df['is_night'] * (df['amount'] > 100000)).astype(int)
    
    # –í—ã—Ö–æ–¥–Ω–æ–π + –Ω–æ—á—å
    df['weekend_night'] = (df['is_weekend'] * df['is_night']).astype(int)
    
    # –ë–æ–ª—å—à–∞—è —Å—É–º–º–∞ + –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    df['large_amount_no_activity'] = ((df['amount'] > 100000) * 
                                       df['is_zero_activity']).astype(int)
    
    # –ö—Ä—É–≥–ª–∞—è —Å—É–º–º–∞ + –Ω–æ—á—å
    df['round_amount_night'] = (df['is_round_10000'] * df['is_night']).astype(int)
    
    # ========== –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê ==========
    
    df = df.replace([np.inf, -np.inf], 0)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df.columns) - 34} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    return df

# ==================== –§–£–ù–ö–¶–ò–ò –í–ê–õ–ò–î–ê–¶–ò–ò ====================

def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Clean', 'Fraud'],
                yticklabels=['Clean', 'Fraud'])
    plt.title(title, fontsize=14, fontweight='bold')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    tn, fp, fn, tp = cm.ravel()
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    metrics_text = f'Accuracy: {accuracy:.3f}\nPrecision: {precision:.3f}\nRecall: {recall:.3f}\nF1: {f1:.3f}'
    plt.text(2.5, 0.5, metrics_text, fontsize=10, 
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    return plt.gcf()

def plot_roc_curve(y_true, y_proba):
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å ROC –∫—Ä–∏–≤—É—é"""
    fpr, tpr, thresholds = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, 
             label=f'ROC curve (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve', fontweight='bold')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    return plt.gcf()

def plot_precision_recall_curve(y_true, y_proba):
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å Precision-Recall –∫—Ä–∏–≤—É—é"""
    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)
    
    plt.figure(figsize=(8, 6))
    plt.plot(recall, precision, color='blue', lw=2)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve', fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    return plt.gcf()

def plot_learning_curves(estimator, X, y, cv=5):
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è"""
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='roc_auc'
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, 'o-', color='r', label='Training score')
    plt.plot(train_sizes, test_mean, 'o-', color='g', label='Cross-validation score')
    
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, 
                     alpha=0.1, color='r')
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, 
                     alpha=0.1, color='g')
    
    plt.xlabel('Training Examples')
    plt.ylabel('AUC Score')
    plt.title('Learning Curves', fontweight='bold')
    plt.legend(loc='lower right')
    plt.grid(True, alpha=0.3)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏
    gap = train_mean[-1] - test_mean[-1]
    if gap > 0.1:
        plt.text(0.5, 0.5, f'‚ö†Ô∏è Overfitting detected!\nGap: {gap:.3f}', 
                transform=plt.gca().transAxes,
                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),
                fontsize=10)
    
    plt.tight_layout()
    return plt.gcf()

def cross_validate_model(model, X, y, cv=5):
    """–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
    print(f"\nüîÑ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (k={cv} —Ñ–æ–ª–¥–æ–≤)...")
    
    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)
    
    # –†–∞–∑–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    scoring_metrics = ['roc_auc', 'precision', 'recall', 'f1']
    results = {}
    
    for metric in scoring_metrics:
        scores = cross_val_score(model, X, y, cv=skf, scoring=metric, n_jobs=-1)
        results[metric] = scores
        print(f"   {metric.upper()}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")
    
    return results

def check_data_leakage(df, feature_cols, target_col='is_fraud'):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö...")
    
    suspicious_features = []
    
    for col in feature_cols:
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        if df[col].dtype in ['int64', 'float64']:
            corr = abs(df[col].corr(df[target_col].astype(int)))
            
            if corr > 0.95:  # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
                suspicious_features.append((col, corr))
                print(f"   ‚ö†Ô∏è {col}: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è = {corr:.4f}")
    
    if suspicious_features:
        print(f"\n   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(suspicious_features)} –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
    else:
        print("   ‚úÖ –£—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    return suspicious_features

# ==================== –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================

def main():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data_from_db()
    
    # Feature engineering
    df = engineer_features_advanced(df)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¢–ï –ñ–ï, –ß–¢–û –í train_improved_model.py)
    feature_cols = [
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—É–º–º—ã
        'amount', 'amount_log', 'amount_sqrt', 'amount_cbrt', 'amount_category',
        'is_round_100', 'is_round_1000', 'is_round_10000',
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        'hour', 'minute', 'day_of_week', 'day_of_month', 'month',
        'is_night', 'is_early_morning', 'is_morning', 'is_afternoon', 'is_evening', 
        'is_weekend', 'is_peak_fraud_hour',
        'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos',
        
        # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        'avg_logins_per_day_30d', 'avg_logins_per_day_7d',
        'avg_session_interval_sec', 'burstiness_score',
        'exp_weighted_avg_interval', 'fano_factor', 'interval_zscore',
        'login_freq_change_ratio', 'login_ratio_7d_30d',
        'logins_last_30_days', 'logins_last_7_days',
        'session_interval_std', 'session_interval_variance',
        'unique_os_versions_30d', 'unique_phone_models_30d',
        'has_os_data', 'has_phone_data', 'device_diversity', 'is_multi_device',
        'has_behavior_data', 'login_activity_score', 'is_zero_activity',
        'is_high_burstiness', 'is_unusual_interval',
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        'night_large_amount', 'weekend_night', 'large_amount_no_activity',
        'round_amount_night'
    ]
    
    X = df[feature_cols]
    y = df['is_fraud'].astype(int)
    
    print(f"\nüìä –î–∞—Ç–∞—Å–µ—Ç:")
    print(f"   –†–∞–∑–º–µ—Ä: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    print(f"   Fraud: {y.sum()} ({y.mean()*100:.1f}%)")
    print(f"   Clean: {(~y.astype(bool)).sum()} ({(1-y.mean())*100:.1f}%)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö
    suspicious = check_data_leakage(df, feature_cols)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–∞–º
    model_files = {
        'LightGBM': Path('models/fraud_model_improved.txt'),
        'CatBoost': Path('models/fraud_model_improved.cbm'),
        'XGBoost': Path('models/fraud_model_improved.json')
    }
    
    model_type = None
    for mtype, mpath in model_files.items():
        if mpath.exists():
            model_type = mtype
            print(f"   üìã –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_type}")
            break
    
    if not model_type:
        print("   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é CatBoost...")
        model_type = 'CatBoost'
    
    try:
        if model_type == 'LightGBM':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –æ–±—ë—Ä—Ç–∫—É
            model = LGBMWrapper('models/fraud_model_improved.txt')
            model.fit(X, y)  # –ó–∞–≥—Ä—É–∑–∏—Ç pre-trained –º–æ–¥–µ–ª—å
            print("   ‚úÖ LightGBM –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        elif model_type == 'CatBoost':
            model = cb.CatBoostClassifier()
            model.load_model('models/fraud_model_improved.cbm')
            print("   ‚úÖ CatBoost –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        elif model_type == 'XGBoost':
            import xgboost as xgb
            model = xgb.XGBClassifier()
            model.load_model('models/fraud_model_improved.json')
            print("   ‚úÖ XGBoost –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
        print("   –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é CatBoost –º–æ–¥–µ–ª—å...")
        
        # –í–µ—Å –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        scale_pos_weight = (len(y) - y.sum()) / y.sum()
        
        model = cb.CatBoostClassifier(
            loss_function='Logloss',
            eval_metric='AUC',
            depth=8,
            learning_rate=0.05,
            iterations=300,
            l2_leaf_reg=3,
            subsample=0.8,
            auto_class_weights='Balanced',
            random_state=42,
            verbose=False
        )
        model.fit(X, y)
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_results = cross_validate_model(model, X, y, cv=5)
    
    # –û–±—É—á–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è CatBoost)
    if model_type == 'CatBoost':
        print("\nüé® –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        model.fit(X, y)
        y_pred = model.predict(X).flatten()
        y_proba = model.predict_proba(X)[:, 1]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        import os
        os.makedirs('validation_plots', exist_ok=True)
        
        # 1. Confusion Matrix
        fig1 = plot_confusion_matrix(y, y_pred, "Confusion Matrix (Full Dataset)")
        fig1.savefig('validation_plots/01_confusion_matrix.png', dpi=150)
        plt.close()
        print("   ‚úÖ Confusion Matrix —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        # 2. ROC Curve
        fig2 = plot_roc_curve(y, y_proba)
        fig2.savefig('validation_plots/02_roc_curve.png', dpi=150)
        plt.close()
        print("   ‚úÖ ROC Curve —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        # 3. Precision-Recall Curve
        fig3 = plot_precision_recall_curve(y, y_proba)
        fig3.savefig('validation_plots/03_precision_recall.png', dpi=150)
        plt.close()
        print("   ‚úÖ Precision-Recall Curve —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        # 4. Learning Curves
        fig4 = plot_learning_curves(model, X, y, cv=5)
        fig4.savefig('validation_plots/04_learning_curves.png', dpi=150)
        plt.close()
        print("   ‚úÖ Learning Curves —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    else:
        print("\n‚ö†Ô∏è –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è CatBoost –º–æ–¥–µ–ª–∏")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 70)
    print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò")
    print("=" * 70)
    
    print("\n1Ô∏è‚É£ –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø (5 —Ñ–æ–ª–¥–æ–≤):")
    for metric, scores in cv_results.items():
        print(f"   {metric.upper()}: {scores.mean():.4f} ¬± {scores.std():.4f}")
    
    print("\n2Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    recall_mean = cv_results['recall'].mean()
    precision_mean = cv_results['precision'].mean()
    f1_mean = cv_results['f1'].mean()
    
    if recall_mean < 0.5:
        print(f"   ‚ö†Ô∏è RECALL –ù–ò–ó–ö–ò–ô ({recall_mean:.1%})")
        print(f"      –ú–æ–¥–µ–ª—å –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç {(1-recall_mean)*100:.0f}% –º–æ—à–µ–Ω–Ω–∏–∫–æ–≤!")
        print(f"      –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"      - –£–≤–µ–ª–∏—á–∏—Ç—å sampling_strategy –¥–æ 0.8")
        print(f"      - –°–Ω–∏–∑–∏—Ç—å –ø–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ 0.3")
        print(f"      - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CatBoost –≤–º–µ—Å—Ç–æ LightGBM")
    elif recall_mean < 0.7:
        print(f"   ‚ö° RECALL –°–†–ï–î–ù–ò–ô ({recall_mean:.1%})")
        print(f"      –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å–Ω–∏–∂–µ–Ω–∏–µ–º –ø–æ—Ä–æ–≥–∞ –∏–ª–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º SMOTE")
    else:
        print(f"   ‚úÖ RECALL –•–û–†–û–®–ò–ô ({recall_mean:.1%})")
    
    if precision_mean < 0.5:
        print(f"   ‚ö†Ô∏è PRECISION –ù–ò–ó–ö–ò–ô ({precision_mean:.1%})")
        print(f"      –ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π")
    elif precision_mean < 0.7:
        print(f"   ‚ö° PRECISION –°–†–ï–î–ù–ò–ô ({precision_mean:.1%})")
    else:
        print(f"   ‚úÖ PRECISION –•–û–†–û–®–ò–ô ({precision_mean:.1%})")
    
    print(f"\n   F1-SCORE: {f1_mean:.4f}")
    
    print("\n3Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê –ù–ê –ü–ï–†–ï–û–ë–£–ß–ï–ù–ò–ï:")
    train_score = cv_results['roc_auc'].mean()
    if train_score > 0.95:
        print("   ‚ö° –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
        print(f"   - AUC = {train_score:.4f}")
    else:
        print("   ‚úÖ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    print("\n4Ô∏è‚É£ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if len(suspicious) > 0:
        print("   ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö")
    if y.sum() < 100:
        print("   ‚ö†Ô∏è –ú–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤ fraud - —Å–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
    if recall_mean < 0.5:
        print("   üîß –°–†–û–ß–ù–û: –ù—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å Recall!")
        print("      1. –ó–∞–ø—É—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å sampling_strategy=0.8")
        print("      2. –ò—Å–ø–æ–ª—å–∑—É–π CatBoost (–æ–Ω –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–∏–π Recall)")
        print("      3. –°–Ω–∏–∑—å –ø–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ 0.3")
    
    if model_type == 'CatBoost':
        print("\nüìÅ –í—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: validation_plots/")
    
    print("\n" + "=" * 70)
    print("‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 70)

if __name__ == "__main__":
    main()